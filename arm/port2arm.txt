Porting hForth to the StrongArm SA-110 RISC processor.
======================================================

1. Background
-------------

Once upon a time I downloaded Julian Noble's FPRIMER.ZIP from a SIMTEL archive
and discovered eForth V1.0. I was fascinated by the way that eForth used an
assembler's macro expansion capability to generate all of the header and
dictionary structures for a Forth compiler. I ported eForth to the Z80 (not
knowing that this had already been done) - I chose the Z80 because I was
familiar with it and I had a development environment for it. Doing the Z80
port was not useful, except as a Great Learning Experience.

At the time that I started playing with eForth, I was working for Digital
Equipment Corporation's semiconductor division (Digital Semiconductor, DS) as
an applications engineer. Having completed the eForth port to the Z80 I was
casting around for another fun spare-time project, and I naturally settled
upon the idea of doing a port to the 64-bit Alpha RISC processor. However,
before I could get started on this project, DS took a license for the Advanced
RISC Machines Ltd ARM architecture, and announced that it was developing
StrongArm. My group won the task of supporting StrongArm chip sales, and I
started work on the design of a board that would be used as a hardware
verification and evaluation platform for the first StrongArm chip, the SA-110.

When the board design was completed I had about a month to spare whilst the
board was in layout and manufacture. The SA-110 itself was still in the last
stages of design. I took some code examples from another engineer, who was
writing the diagnostic and test code, and set about the task of learning ARM
assembler programming, with a view to porting eForth to the SA-110.

I debugged the ARM eForth port on an instruction-set simulator, and then on an
ARM610 processor evaluation board. Meanwhile, my board had come back from
assembly and I had done as much testing as you can do on a processor board
when it has no processor. Boards were shipped to Austin, Texas where the
SA-110 design team were headquartered, and I eagerly awaited SA-110
prototypes.

Finally, we had word that the SA-110 was due out of fab imminently. Myself and
a software engineer travelled to Austin. We powered the very first SA-110 chip
up in the last week of November, 1995 and, within a day, the diagnostics were
up and running (well done, Anthony). The code for talking to the debug tools
presented more of a problem and there wasn't much I could do to help. It was
time to blow an EPROM on my own account..

A couple of days (and many cycles through the EPROM eraser) later eForth was
up and running (it was the third or fourth program ever to run on SA-110
silicon). It was immediately useful for writing code one-liners to exercise
logic and measure power consumption. In addition, I added facilities to allow
the processor's caches to be turned on and off under software control so that
we could measure the impact on speed and power consumption.

Overall, eForth proved to be very useful during the course of the project, but
in the meantime I had discovered the ANS standard, and I wanted to try some of
the features that eForth lacked. I began to modify eForth to bring it in line
with the ANS standard. One day, during a bit of web browsing, I came across Dr
Wonyong Koh's hForth[1]. When I saw what Dr Koh had achieved, using eForth as
a starting point, I abandoned eForth and started a port of hForth.


2. Problems
-----------

There were three basic problems to address:

- Coding low-level routines for the target processor
- Tool chain
- Portability issues in the code


2.1 Coding low-level routines for the target processor
------------------------------------------------------

hForth is a direct threaded code (DTC) Forth, and it is designed to be built
using a macro assembler. Macros are used in the source code to express Forth
constructs like constants, variables, colon definitions and code definitions.
To simplify the porting effort, a minimal number of definitions must be coded
in assembler; the remainder are colon definitions. The first step in the
porting process is to map registers of the Forth virtual machine to real
registers in the target processor. The ARM has 15 general-purpose registers,
named R0 through R14; R15 is the program counter. R14 has a special role
during subroutine calls; it stores the return address from the subroutine
(unlike CISC processors, RISC processors do not tend to have dedicated
hardware stack pointers). The instruction set is highly orthogonal (another
RISC characteristic) so it makes little difference which register is used for
which function. I chose this register assignment:

Name	Register	Description
-----------------------------------
dsp	R12		Data stack pointer
rsp	R11		Return stack pointer
fpc	R10		Forth virtual machine program counter
tos	R9		Top of (data) stack

The assembler source defines aliases for these four registers so that they can
be referred to by name.

Having allocated registers, the second stage in the porting process is to
design the virtual machine and code the low-level routines. The main
difference between eForth and hForth in these areas is that hForth uses the
common technique of keeping top-of-stack in a processor register. That meant
that I could reuse much of my existing code with only minor modifications. In
any case, the amount of work is small; in ARM assembler the longest "required"
code definition is about 10 lines of assembler code. The hForth source
highlights a number of words that should be coded in assembler for speed, but
also provides colon definitions that can be used during the initial debug of a
new port.


2.1.1 Example code fragments
----------------------------

This section shows how hForth definitions are expressed in the assembler
source and how the macros expand to generate code for the target. The ARM and
8086 implementations are compared by considering this colon definition:

: DOUBLE ( n -- n ) DUP + ;

In the source code, this could be represented as a colon definition, which
would be portable across processors:

 $COLON 6,'DOUBLE',DUBBLE,_SLINK
 DEFW DUP,PLUS,EXIT

"$COLON" is a macro that expands to perform 3 tasks:

- generate an entry in the name dictionary for the word DOUBLE, and associate
  an XT with the name. The value of the XT is the assembler label DUBBLE, and
  its value is a forward reference that will be resolved by the assembler in
  the usual way. "_SLINK" is an assembler variable that is used to build a
  link to the previous entry in the name dictionary. By using different
  variables here, multiple wordlists can be intertwined in the name
  dictionary.
- generate a label in the code dictionary with the name DUBBLE
- generate a processor-dependent call to the inner interpreter, DoLIST.

"DEFW" is an assembler pseudo-op, and is followed by a list of labels. Each
label corresponds to an XT that will have been created by some other macro
expansion. The labels may be forward or backward references because they will
all be resolved by the assembler in the usual way. In this example, the values
will be the XTs for "DUP", "+" and "EXIT" respectively.

For the 8086, the cell size is 16 bits and the opcode size is variable. The
call to the inner interpreter is a call to an absolute address. The opcode for
CALL is 1 byte, and so this is prefixed with a 1-byte NOP to keep the code
aligned to a cell boundary. The definition looks like this:

      NOP		1 byte	       } Macro expansion.. processor
      CALL DoLIST	1 + 2 bytes    } native code
      XT-DUP		2 bytes	      }
      XT-+		2 bytes	      }  Executed by inner interpreter
      XT-EXIT		2 bytes	      }  on Forth Virtual Machine

DoLIST is a label, resolved by the assembler. The XTs are absolute addresses.
The CALL pushes a return address onto the hardware stack and this return
address is used by the inner interpreter to access the XTs that make up the
definition.

For the ARM, the cell size and the opcode size are both 32 bits; the
definition looks like this:

      BL DoLIST		4 bytes	       } Macro expansion.. processor
					 native code
      XT-DUP		4 bytes	      }
      XT-+		4 bytes	      }  Executed by inner interpreter
      XT-EXIT		4 bytes	      }  on Forth Virtual Machine

The BL (branch-and-link) instruction is a single 32-bit opcode. Rather than
specifying an absolute address, the branch destination (to the label DoLIST)
is encoded as a 24-bit, signed, PC-relative offset within the opcode. This
only makes a sub-set of the 32-bit address space accessible, but the range is
more than adequate. As before, the XTs are absolute addresses. The BL stores a
return address in the processor register R14 (R14 must be preserved before
another BL can be executed). The value of R14 is used by the inner interpreter
to access the XTs that make up the definition.

The result of using the $COLON macro is that the colon definition of DOUBLE is
portable, even though the macro and result of the macro expansion are not
portable. Next, we will look at how the same definition would be expressed as
a (processor-dependent) code definition. For the 8086 it looks like this:

 $CODE 6,'DOUBLE',DUBBLE,_SLINK
 MOV AX, BX
 ADD BX, AX
 $NEXT

While for the ARM it looks like this:

 $CODE 6,'DOUBLE',DUBBLE,_SLINK
 ADD	tos,tos,tos
 $NEXT

The macro "$CODE" expands out to generate a label and a name dictionary entry
as before, but does not generate anything in the code dictionary. The macro
"$NEXT" terminates the definition by returning control to the caller of this
definition. Everything in between is expanded by the assembler to generate
opcodes for the particular processor. Remember that "tos" is simply an alias
for the register R9, which is used to hold the top-of-stack value.

For the 8086, the expansion of $NEXT generates this code:

 LODSW	    ; get the next code address into AX
 JMP AX	    ; jump directly to the code address

Whilst for the ARM, the expansion of $NEXT generates this code:

 MOV   pc,[fpc], #CELLL

This instruction can be read as "load the PC (ie branch to) with the value
that is stored in the cell addressed by the current value of fpc, and
post-increment fpc (by the cell-size) to address the subsequent cell".
    
To understand these examples more clearly we need to see how the inner
interpreter, DoLIST, is implemented. Remember from the discussion above that
DoLIST takes an input parameter; the address of the first XT to be executed,
and that this parameter is passed to the DoLIST code in a processor-specific
way:

- For the 8086, DoLIST is entered through a native CALL, and the parameter is
  passed on the hardware stack since it is the return address for the call.

- For the ARM, DoLIST is entered through a native BL and the parameter is
  passed in R14, since this is the return (link) address for the BL.

For the 8086, DoLIST looks like this:

 $CODE	COMPO+6,'doLIST',DoLIST,_SLINK
 SUB	BP,2
 MOV	[BP],SI 		;push return stack
 POP	SI			;new list address
 $NEXT

For the ARM, DoLIST looks like this:

 $CODE	COMPO+6,'doLIST',DoLIST,_SLINK
 STR	fpc, [rsp, # - CELLL]!	;preserve forth PC
 MOV	fpc, R14		;first xt of definition
 $NEXT

The STR (store) instruction performs a store of the current fpc value onto the
return stack and then updates the fpc with the parameter passed in R14. The
"[rsp , # - CELLL]!" means store at the location addressed by rsp but first
decrement rsp by the value of CELLL -- in other words, this instruction
implements a "push" with rsp as the stack pointer and fpc as the data.

Now that we've seen how definitions are generated by the assembler, there's
one final thing we need to consider; the processor-dependent parts of
generating a new definition when hForth is up and running on the target.
Again, we will consider the definition for DOUBLE.

The only processor-dependent part of the compilation process is the generation
and detection of the call to DoLIST. In hForth this is handled by the words
"?call" and "xt,". "?call" is used to check whether a given location contains
a direct threaded code call; it is used for optimisation purposes and by SEE
(the word decompiler). "xt," takes an XT as a parameter and compiles a direct
threaded code call to that location.

8086 versions, where call-code is 0xE890 (opcode for a NOP followed by a CALL):

: ?call	DUP @ call-code =
  IF   CELL+ DUP @ SWAP CELL+ DUP ROT + EXIT THEN
		\ Direct Threaded Code 8086 relative call
		0 ;

: xt,	xhere ALIGNED DUP TOxhere SWAP
	call-code code, 	\ Direct Threaded Code
	xhere CELL+ - code, ;	\ 8086 relative call

ARM versions, where call-code is 0xEB000000 (opcode for BL, with an offset of
0):

: ?call DUP @ 0ff000000h AND call-code =
	IF DUP DUP @ 00ffffffh AND    \ it's a branch.. get offset
	   DUP 007fffffh > IF
	       00ff000000h OR \ sign extend the offset
	   THEN
	   2 LSHIFT                      \ convert to byte offset
	   + CELL+ CELL+                 \ fix up for pipeline prefetch
	   SWAP CELL+ SWAP EXIT
	THEN 0 ;

: xt,	xhere ALIGNED DUP TOxhere SWAP
	xhere - cell- cell- 2 RSHIFT    \ get signed offset
	00ffffffh AND                   \ mask off high-order sign bits
	call-code OR                    \ make the opcode 
	xhere swap                      \ remember where it will go
	code, IDflushline ;		\ emit it and purge the block

The final call to IDflushline is required to support the caches on the
SA-110, and it is discussed further below.


2.2 Tool chain
--------------

eForth and hForth both rely on macro expansion in an 8086 assembler in order
to build code and name dictionaries for the target image. Some ports to other
processors have continued to use the 8086 macro assembler; in this technique,
the low-level words are hand-assembled and edited into the assembler source
files as DEFW (define word) statements. This is somewhat tedious but entirely
effective. That technique was unsuitable for the ARM port because the 8086
macro assembler is designed to use 16-bit addresses whereas the ARM uses
32-bit addresses. Therefore, it was logical to use the assembler and linker in
ARM Ltd's Software Development Toolkit (SDT). This is where I hit a major
problem. The macros work by repeatedly changing the value of "ORG" -- the
position in the target image at which code/data is being generated. They do
this because each macro expansion generatess stuff in both the code dictionary
and name dictionary, and these are in separate memory areas. The problem is
that the ARM assembler does not allow ORG to be changed. (At the time that I
learned this, it came as something of a shock. I have since learnt that it is
a common restriction in modern single-pass assemblers).

The only solution to this problem was to change the structure of the assembler
source so that every definition was broken into two parts (one that generated
code dictionary entry and one that generated name dictionary entry). Rather
than embarking on a major editing session, I used the scripting language, AWK
to process the assembler source. I ended up with three separate scripts:

- The first script mades syntax changes to the assembler source to suit the
  ARM assembler
- The second script expands all the macros and generates three output files;
  one representing the code dictionary, one representing the name dictionary
  and one representing a jump table and ASCII strings for the system THROW
  (error) messages
* The third script reverses the order of the entries in the name dictionary so
  that entries logically grow down from high memory

The assembler source is run through these three scripts and the three output
files (code dictionary, reversed name dictionary and throw table) are
concatenated and fed through the ARM assembler. The final stage is to link
them using the ARM linker. The entire build processs takes about 5 seconds.

The AWK scripts took some weeks to develop, but I had already made that
investment for eForth, and the modifications for hForth were relatively minor
(for example, adding the throw table, since this was not present in
eForth). The whole process had a major benefit that I did not anticipate; my
assembler source file had a relatively small number of changes from the 8086
version. When Dr Koh made new releases of his code, I was able to use the
excellent "ediff" feature in GNU Emacs to view differences between my old code
and Dr Koh's new release, and patch (with a single keystroke) any revision
that affected my port.


2.3 Portability issues
----------------------

eForth and hForth were originally written for a 16-bit processor, the 8086,
with a 16-bit cell size. My target machine was a 32-bit processor, with a
32-bit cell size. I had found a couple of places in eForth (loop counters in
the division and multiplication routines) where the code relied on a 16-bit
cell size and I had changed these to get the 32-bit version working. I checked
for these same problems in hForth but I found that they had already been
abstracted to a constant, cell-size-in-bits. I was later able to conclude that
there were no portability issues in the code related to cell size (at least,
none that affected the transition from 16 to 32 bits). In addition, as Dr Koh
predicted[1], the multi-tasker ran without modification.

One area that limited portabilty was an environment string called systemID.
As previously described in [1], hForth has three closely associated
implementations; ROM model, RAM model and EXE model. Different assembler
source code is used to build each model, and generates the basic kernel of the
Forth system. Additional functionality is added by INCLUDEing Forth source
files on the running system. The definitions in these files are coded to work
correctly for any of the models. Where data structures vary for the different
models, systemID is tested to see which version to use. Originally, the
environment string systemID expanded to "8086 ROM Model".  For the ARM port,
this was changed to "ARM ROM Model", but this stopped the Forth source files
from working. Dr Koh revised hForth to solve this problem; he split the
environment string into two parts; CPU (for example, "8086") and Model (for
example, "ROM Model"). As a result, most of the high-level files only needed
to test Model, and became CPU-independent. The only time where the CPU
environment string must be tested is for definitions that use (CPU-dependent)
assembler. For example:

CHAR " PARSE CPU" ENVIRONMENT? DROP
CHAR " PARSE 8086" COMPARE
[IF] DROP
  CODE D-
      BX DX MOV,	AX POP,		BX POP,      CX POP,      AX CX SUB,
      CX PUSH,		DX BX SBB,      NEXT,
  END-CODE
[ELSE]
  : D-	 DNEGATE D+ ;
[THEN]


3. Additions to the functionality
---------------------------------

In addition to re-coding the low-level routines, I made these modifications to
hForth:

- Changed the I/O to support simple terminal I/O and file download
- Added some primitive code to help in the debug of new ports
- Added support for processor caches


3.1 I/O routines
----------------

The 8086 hForth is designed to run under MSDOS. It uses software interrupts to
DOS to perform character I/O and file I/O. My target platforms had no
underlying operating environment and so I had to write initialisation code for
the system memory controller and I/O devices, and character input and output
routines to control a UART. I connected to the UART on the target using an
RS232 connection from a PC running a terminal emulator.

I added a simple file download function, which relies on a ASCII file download
from the terminal emulator and XON/XOFF flow control within hForth. This
facility copies the FILE/HAND technique used by eForth.

All of the target boards that I ran hForth on had on-board Flash ROM. hForth
was stored in ROM but copied into RAM at startup so that it would run more
quickly. I added Forth definitions to allow me to take a running RAM image of
hForth (including all the definitions that had been added interactively or by
file download) and program this image back into Flash.


3.2 Debugging
-------------

The initial debug of both the eForth and hForth ports was done using ARM Ltd's
SDT. This includes an instruction set simulator that runs under the control of
a debugger to allow single-stepping, source-level debug and breakpointing.

Both eForth and hForth use a minimal number of words defined in machine code
(code definitions); the bulk of the image consists of the name dictionary
(which the debugger just treats as data) and threaded lists of execution
tokens. By definition, a breakpoint can only be set on an opcode, and for a
DTC Forth there is only one opcode in each colon definition; the DTC call to
DoLIST.

Simply trapping on the call to DoLIST leads to multiple unwanted traps.  For
example, consider a definition that includes this fragment:

    R> SWAP 2DUP + ALIGNED >R

If a breakpoint is set on the call to DoLIST for each of these words, the
breakpoint would also be triggered if, for example, the definition of ALIGNED
used SWAP. It would be useful to step through each word in turn (and check the
effect upon the stacks and other data areas) without diving down into other
definitions. The threaded nature of the code makes it very difficult to step
through a particular definition in this way using breakpoints.

Conventional Forth programming philosophy encourages you to test and debug
each low-level word and work your way upwards to a complete debugged
program. However, when you are trying to bring up Forth with no particular
tools to help you, you have no "test harness" to exercise a word other than
the entirety of the Forth compiler.

My solution to this problem was to modify $NEXT to implement a "micro
debugger", uDebug.

All definitions end with $NEXT -- either directly (code definitions) or
indirectly (colon definitions terminating in EXIT, which is itself a code
definition). The normal action of $NEXT is to use the fpc to fetch the XT of
the next word and jump to it. The modified action of $NEXT is to make a jump
(not a call) to the routine uDebug. Invoking this modified behaviour is a
build-time option that requires you to reassemble the code.

In ARM assembler, uDebug looks like this:

uDebug          ldr r0,=AddrTrapfpc
		ldr r1,[r0]
		cmps r1,fpc             ; compare the stored address with
					; the address we're about to get the
					; next xt from
		ldrne pc, [fpc], #CELLL ; not the trap address, so we're done
		add r1,fpc,#CELLL       ; next time trap on the next xt
		str r1, [r0]
		ldr pc, [fpc], #CELLL   ; make debugger TRAP at this address


To invoke uDebug for a particular definition:

1. Set a debugger breakpoint at the DTC call to DoLIST at the start of the
   definition to be debugged, and run until you hit this breakpoint.
2. Load the location trapfpc with the address of the first XT in the
   definition to be debugged.
3. Set a debugger breakpoint on the final instruction in the uDebug routine.

When you run the code, the debugger will now trap after the execution of the
first XT in the definition. Run again and it will stop after the execution of
the second. To disable uDebug, set the location trapfpc to 0.

This technique has a number of limitations:

- It depends upon an XT of 0 being illegal (since this acts as a magic value
  to turn uDebug off)

- It does not allow you to automatically debug a code stream that includes
  inline string definitions, or any other kind of inline literal; you must
  step into the word that includes the definition then hand-edit the
  appropriate new value into trapfpc.

These limitations could be overcome by making uDebug more complex -- but at a
risk of introducing bugs into the debugger code itself. uDebug has now been
incorporated into Dr Koh's hForth source.

Another technique that I used early in eforth debug was even simpler; a
definition called DXIT, which has identical behaviour to EXIT, but with a
different XT. To use this to debug a definition:

1. Set a debugger breakpoint on the DTC call at the start of DXIT

2. In the definition to be debugged, patch the XT of EXIT with the XT of DXIT 

Now when you run the code, the debugger will trap at the end of the definition
to be debugged; an ideal point at which to examine the stack effects. A
duplicate DoLIST could be used in a similar way but, for the ARM, patching in a
BL to DoLIST requires a fiddly calculation of a relative offset.

Once hForth was up and running on my target hardware, I re-coded some colon
definitions as code definitions, to improve performance. I started by giving a
code definition a different name from its colon definition and debugging it
interactively. After testing, I replaced the colon definition with the code
definition and reassembled.


3.3 Caches
----------

Everything that has been described so far applies equally to SA-110 and any
other ARM processor. However, the architecture of the SA-110 caches differs
from that of earlier ARM processors. In common with many RISC processors, but
unusually for an ARM processor, the SA-110 has a modified Harvard
architecture; separate instruction and data caches but a unified 32-bit
address space accessed through a single external bus interface. This cache
architecture introduced two problems for the hForth port:

- keeping the I-cache coherent during code generation
- achieving high cache utilisation


3.3.1 Cache coherence
---------------------

As is usual on RISC processors, the SA-110 has no hardware mechanism to keep
the I-cache coherent with the rest of the system (D-cache and main
memory). Therefore, whenever a value is written into memory and that value is
to be used as an opcode, the coherence of the caches must be enforced under
software control. This has two well-known consequences:

- self-modifying code requires careful attention
- after loading a new executable image into memory, the caches must be
  flushed before the code can be executed 

Forth can be regarded as a special case of self-modifying code, in the sense
that an image that is executing makes additions to its own code space. When
hForth is running, the only opcode generated is the "BL DoLIST" at the start
of a definition. This is generated by "xt," and so, for the ARM port, "xt,"
was modified by the addition of a call to "IDflushline". The function of
IDflushline is to take an address and to force cache coherence at that
address. The SA-110 has a write-through data cache and therefore, the sequence
performed by IDflushline is:

- clean D-cache entry at this address (force dirty data line to main memory)
- flush I-cache entry (force a cache miss at this address)

Subsequently, an opcode fetch from the address will cause the I-cache to miss
and force the opcode to be fetched from main memory.

For a system without caches, or where I-cache coherence is enforced in
hardware, IDflushline can simply be "DROP".


3.3.2 Cache utilisation
-----------------------

Consider what happens when the colon definition of DOUBLE is executed for the
first time. Recall that the definition occupies 16 bytes:

      [BL DoLIST] [XT-DUP] [XT-+] [XT-EXIT]

To start execution of the word, the SA-110's program counter is loaded with
the address of the "BL DoLIST". The SA-110 checks the I-cache to see if a
value for this address is present, and cache misses. A cache miss is serviced
by loading a naturally-aligned block of 8 32-bit words from main memory into
the cache (in this case, the I-cache). The size of the block is called the
"line size", and results in 7 other 32-bit words being read into the
I-cache. Depending upon the alignment of DOUBLE in memory, some of these words
may be part of the definition of DOUBLE or they may be values associated with
earlier or later definitions in memory. Once the cache-miss data has been
loaded, the SA-110 executes the BL and branches to the inner interpreter which
will generate a fetch from the address at which [XT-DUP] is stored. This fetch
is a *data* fetch, and so the SA-110 checks the D-cache and, again, cache
misses. Again, the miss is serviced by loading a naturally-aligned block of 8
32-bit words into the D-cache. Often, these will be exactly the same 8 words
that are already stored in the I-cache.

This example shows that intermingling code and data leads to low cache
utilisation; the I-cache is polluted with XTs that can only be used as data
and, to a lesser extent, the D-cache is polluted with branches to DoLIST,
which can only be executed as instructions.

Cache utilisation is a "figure of merit" for a piece of code; it is calculated
as the proportion of values that, having been loaded into a cache line, are
subsequently used at least once before being discarded to make way for some
other value. Low cache utilisation reduces performance for two reasons:

- the processor is stalled whilst the cache line is loaded; loading values
  that never get used wastes processing cycles
- compared with an ideal system (one with full cache utilisation), the system
  performs as though it had a cache that is only a fraction of its actual size.

Intermingled code and data would be more appropriate for a system with a
unified cache, but this architecture is rarely used in high-performance
systems because a modified Harvard architecture is an easy way of increasing
the instruction/data bandwidth into a processor core.

For the SA-110, the cache utilisation could be improved dramatically by
changing from a direct threaded code to a subroutine threaded code
implementation. This would eliminate the "BL DoLIST" at the start of each
definition, and change the list of XTs in a definition to a list of "BL"
instructions. The design of the compiler and decompiler would be complicated
slightly, but the whole thing could probably be factored efficiently and
incorporated into hForth as a build-time option.


4. Applications of hForth
-------------------------

My use of hForth on SA110-based target systems has been for testing and
debugging hardware. Since the ARM port was released, there have been a few
sightings of its use elsewhere; including modifications to the build procedure
to support the use of the GNU ARM assembler/linker.


5. Other projects in progress
-----------------------------

The frustration of having to use AWK scripts to preprocess the assembler
source file led me to start thinking about other ways to generate an
executable image. Several Forth implementations have successfully used C as a
source environment, but I was reluctant to go down that path because the
existing structure of hForth makes it suitable for processors for which no C
compiler is available.

The logical solution is to meta-compile hForth and thereby do away with any
external tool problems. I have a prototype system running on pfe (a 32-bit ANS
Forth compiler) under Linux. After loading two ANS programs (an ARM assembler
and the meta-compiler) it it then possible to read in the hForth source
(somewhat modified, since the source is now entirely expressed in Forth) and
spit out an ARM binary. More about that in another article...


6. Conclusions
---------------

hForth lived up to its author's goal of being easily portable to other
processors. If you want a public-domain forth that runs on an embedded target, 
it is worthy of serious consideration.


A. Acknowledgments [small type]
------------------

I am grateful for Dr Koh's timely responses to numerous emails when I asked
questions about various aspects of his implementation that were unclear to
me. We should all be grateful that Dr Koh was kind enough to take comments and
code fragments back from many people and use them to improve the clarity and
portability of his source code.

Most of the work I did on porting hForth to the SA-110 was done in my private
time. However, some of it was also supported by my then-employer, and I am
grateful to acknowledge Digital Semiconductor's permission to place all of
this work in the public domain under the same restrictions as Dr Koh's
original work: ALL commercial and non-commerical uses are granted.


B. Potted biography [small type]
-------------------

Neal Crook graduated from Southampton University in 1984 with a BSc in Physics
with Electronics. His day-job is as a hardware engineer, working on system
designs and high-performance ASICs and he is co-named inventor on 9 granted
patents in the field of data communications. In his spare time, Neal likes to
ski, cycle, eat, cook and travel the world (oh, and program). Neal can be
contacted at nac@forth.org


A. Download [check these addresses]
-----------

hForth packages for the 8086, Z80 and StrongARM are on-line at:
http://taygeta.com/forth.html or ftp://taygeta.com/pub/Forth/Reviewed. These
packages include an HTML version of Dr Koh's article from FD XV111/2.


B. References
-------------
[1] "hForth: a Small, Portable ANS Forth" Wonyong Koh, FD XV111/2.

[end]
